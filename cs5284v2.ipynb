{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3054,
     "status": "ok",
     "timestamp": 1732245042743,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "_1nwalsd_vSJ",
    "outputId": "101d5939-f4e8-4f6e-d72d-ca5048eba33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1732245052074,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "WDdjYAs5_oTa"
   },
   "outputs": [],
   "source": [
    "data_addr = '/content/drive/MyDrive/cs5284pro/dow_1day_price.csv'\n",
    "adj_addr = '/content/drive/MyDrive/cs5284pro/dow_1day_090_01_corr.csv'\n",
    "s_index = 0\n",
    "lr = 1e-3\n",
    "n_neurons = 128\n",
    "seq_len = 12\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "n_off = 0\n",
    "th = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1732245056341,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "XUd7fJVV_iqy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "class GCGRUCell(nn.Module):\n",
    "    def __init__(self, num_units, adj, num_gcn_nodes, s_index):\n",
    "        super(GCGRUCell, self).__init__()\n",
    "        self.units = num_units\n",
    "        self._gcn_nodes = num_gcn_nodes\n",
    "        self.s_index = s_index\n",
    "\n",
    "        # Preprocess adjacency matrix\n",
    "        adj = self.calculate_laplacian(adj)\n",
    "        # if isinstance(adj, sp.coo_matrix):\n",
    "        # adj = adj.toarray()  # Convert to a dense NumPy array\n",
    "        self.register_buffer(\"_adj\", adj)  # Save as a non-trainable buffer\n",
    "\n",
    "        # GCN weights\n",
    "        self.w0 = nn.Parameter(torch.randn(1, self.units))\n",
    "\n",
    "        # GRU weights\n",
    "        self.wz = nn.Linear(self.units, self.units, bias=True)\n",
    "        self.wr = nn.Linear(self.units, self.units, bias=True)\n",
    "        self.wh = nn.Linear(self.units, self.units, bias=True)\n",
    "\n",
    "        self.uz = nn.Linear(self.units, self.units, bias=False)\n",
    "        self.ur = nn.Linear(self.units, self.units, bias=False)\n",
    "        self.uh = nn.Linear(self.units, self.units, bias=False)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.units\n",
    "\n",
    "    def calculate_laplacian(self, adj):\n",
    "        adj = adj + torch.eye(adj.size(0))  # Add self-loops\n",
    "        degree = torch.sum(adj, dim=1)\n",
    "        degree[degree==0] = 1\n",
    "        d_inv_sqrt = torch.diag(torch.pow(degree, -0.5))\n",
    "        laplacian = d_inv_sqrt @ adj @ d_inv_sqrt\n",
    "        return laplacian\n",
    "\n",
    "    def gc(self, inputs):\n",
    "        # Graph convolution: Ax\n",
    "        ax = torch.matmul(inputs, self._adj)\n",
    "\n",
    "        # Select specific nodes\n",
    "        ax = ax[:, self.s_index]\n",
    "\n",
    "        # Expand last dimension\n",
    "        ax = ax.unsqueeze(-1)\n",
    "\n",
    "        # Transform features\n",
    "        return torch.matmul(ax, self.w0)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        x = self.gc(inputs)\n",
    "\n",
    "        # GRU gates\n",
    "        z = torch.sigmoid(self.wz(x) + self.uz(state))\n",
    "        r = torch.sigmoid(self.wr(x) + self.ur(state))\n",
    "        h = torch.tanh(self.wh(x) + self.uh(r * state))\n",
    "\n",
    "        # Update state\n",
    "        output = z * state + (1 - z) * h\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1732245070683,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "BMKeLSpD_aBf"
   },
   "outputs": [],
   "source": [
    "class GCGRUModel(nn.Module):\n",
    "    def __init__(self, cell, seq_len, num_gcn_nodes):\n",
    "        super(GCGRUModel, self).__init__()\n",
    "        self.cell = cell\n",
    "        self.seq_len = seq_len\n",
    "        self.num_gcn_nodes = num_gcn_nodes\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        state = torch.zeros(batch_size, self.cell.units).to(x.device)\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(self.seq_len):\n",
    "            state = self.cell(x[:, t, :], state)\n",
    "            outputs.append(state)\n",
    "\n",
    "        return torch.stack(outputs, dim=1)  # (batch_size, seq_len, units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1732245073820,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "yUbk0VysIX0_"
   },
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    \"\"\"Normalized adjacency matrix A_hat = D^-0.5 A D^-0.5\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    normalized_adj = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "    return normalized_adj.astype(np.float32)\n",
    "\n",
    "def load_dow_price_data(data_addr, adj_addr):\n",
    "    data = pd.read_csv(data_addr).values\n",
    "    adj = pd.read_csv(adj_addr, header=None).values\n",
    "    # data = normalize(data, axis=0)\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    return data, adj\n",
    "\n",
    "def preprocess_data(data, labels, time_len, train_rate, seq_len, pre_len):\n",
    "    X, Y, pre_Y = [], [], []\n",
    "    for i in range(time_len - seq_len - pre_len):\n",
    "        X.append(data[i:i + seq_len, :])\n",
    "        Y.append(labels[i + seq_len:i + seq_len + pre_len])\n",
    "        pre_Y.append(labels[(i + seq_len - 1):(i + seq_len + pre_len - 1)])\n",
    "\n",
    "    # Split the training set and test set\n",
    "    train_size = int(train_rate * len(X))\n",
    "    X_train = np.array(X[:train_size])\n",
    "    Y_train = np.array(Y[:train_size])\n",
    "    X_test = np.array(X[train_size:])\n",
    "    Y_test = np.array(Y[train_size:])\n",
    "    # pre_Y_test = labels[train_size + seq_len:train_size + seq_len + len(X_test)]\n",
    "    pre_Y_test = np.array(pre_Y[train_size:])\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, pre_Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1732245078499,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "qSwSqbdBAad7",
    "outputId": "e9d94d3c-36b8-4eba-f9a2-1c4fd3f44bfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ae657d590bf0>:5: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "data, adj = load_dow_price_data(data_addr, adj_addr)\n",
    "adj = normalize_adj(adj)\n",
    "if isinstance(adj, sp.coo_matrix):\n",
    "    adj = adj.toarray()  # Convert to a dense NumPy array\n",
    "labels = data[:, s_index]\n",
    "if n_off > 0:\n",
    "    data = data[:-n_off]\n",
    "    labels = labels[n_off:]\n",
    "\n",
    "train_rate = 0.8\n",
    "pre_len = 1\n",
    "time_len = data.shape[0]\n",
    "n_gcn_nodes = data.shape[1]\n",
    "\n",
    "X_train, y_train, X_test, y_test, pre_y_test = preprocess_data( data, labels, time_len, train_rate, seq_len, pre_len)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27378,
     "status": "ok",
     "timestamp": 1732245109503,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "ngBdnOgqKV5I",
    "outputId": "0e34c2f9-b54d-41af-89d2-b4217eae7377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.3466346263885498\n",
      "Epoch 2/100, Loss: 0.12062768638134003\n",
      "Epoch 3/100, Loss: 0.019313275814056396\n",
      "Epoch 4/100, Loss: 0.004977640695869923\n",
      "Epoch 5/100, Loss: 0.02359420619904995\n",
      "Epoch 6/100, Loss: 0.04325191304087639\n",
      "Epoch 7/100, Loss: 0.054792653769254684\n",
      "Epoch 8/100, Loss: 0.058269768953323364\n",
      "Epoch 9/100, Loss: 0.055615611374378204\n",
      "Epoch 10/100, Loss: 0.04879026859998703\n",
      "Epoch 11/100, Loss: 0.03952440619468689\n",
      "Epoch 12/100, Loss: 0.029365815222263336\n",
      "Epoch 13/100, Loss: 0.019721608608961105\n",
      "Epoch 14/100, Loss: 0.01182551309466362\n",
      "Epoch 15/100, Loss: 0.006611766759306192\n",
      "Epoch 16/100, Loss: 0.00449924822896719\n",
      "Epoch 17/100, Loss: 0.005169584881514311\n",
      "Epoch 18/100, Loss: 0.00760465394705534\n",
      "Epoch 19/100, Loss: 0.010456779040396214\n",
      "Epoch 20/100, Loss: 0.012524611316621304\n",
      "Epoch 21/100, Loss: 0.013134594075381756\n",
      "Epoch 22/100, Loss: 0.012241979129612446\n",
      "Epoch 23/100, Loss: 0.010275186970829964\n",
      "Epoch 24/100, Loss: 0.0078697195276618\n",
      "Epoch 25/100, Loss: 0.005622196476906538\n",
      "Epoch 26/100, Loss: 0.0039364988915622234\n",
      "Epoch 27/100, Loss: 0.0029763830825686455\n",
      "Epoch 28/100, Loss: 0.002699272707104683\n",
      "Epoch 29/100, Loss: 0.002930191345512867\n",
      "Epoch 30/100, Loss: 0.0034400830045342445\n",
      "Epoch 31/100, Loss: 0.004007773473858833\n",
      "Epoch 32/100, Loss: 0.0044590262696146965\n",
      "Epoch 33/100, Loss: 0.00468474579975009\n",
      "Epoch 34/100, Loss: 0.004643542226403952\n",
      "Epoch 35/100, Loss: 0.004353816621005535\n",
      "Epoch 36/100, Loss: 0.003879357362166047\n",
      "Epoch 37/100, Loss: 0.0033112219534814358\n",
      "Epoch 38/100, Loss: 0.0027480628341436386\n",
      "Epoch 39/100, Loss: 0.0022769684437662363\n",
      "Epoch 40/100, Loss: 0.0019573175814002752\n",
      "Epoch 41/100, Loss: 0.001810388988815248\n",
      "Epoch 42/100, Loss: 0.0018172303680330515\n",
      "Epoch 43/100, Loss: 0.001925935735926032\n",
      "Epoch 44/100, Loss: 0.002067101653665304\n",
      "Epoch 45/100, Loss: 0.0021734312176704407\n",
      "Epoch 46/100, Loss: 0.0021976232528686523\n",
      "Epoch 47/100, Loss: 0.0021229791454970837\n",
      "Epoch 48/100, Loss: 0.001963831717148423\n",
      "Epoch 49/100, Loss: 0.0017566793831065297\n",
      "Epoch 50/100, Loss: 0.0015461182920262218\n",
      "Epoch 51/100, Loss: 0.0013708100887015462\n",
      "Epoch 52/100, Loss: 0.0012537686852738261\n",
      "Epoch 53/100, Loss: 0.0011989547638222575\n",
      "Epoch 54/100, Loss: 0.0011937981471419334\n",
      "Epoch 55/100, Loss: 0.0012156375451013446\n",
      "Epoch 56/100, Loss: 0.0012395097874104977\n",
      "Epoch 57/100, Loss: 0.0012450264766812325\n",
      "Epoch 58/100, Loss: 0.0012208422413095832\n",
      "Epoch 59/100, Loss: 0.0011661122553050518\n",
      "Epoch 60/100, Loss: 0.001089097699150443\n",
      "Epoch 61/100, Loss: 0.0010036533931270242\n",
      "Epoch 62/100, Loss: 0.000924685678910464\n",
      "Epoch 63/100, Loss: 0.0008638064027763903\n",
      "Epoch 64/100, Loss: 0.0008263188065029681\n",
      "Epoch 65/100, Loss: 0.0008103032014332712\n",
      "Epoch 66/100, Loss: 0.0008079849649220705\n",
      "Epoch 67/100, Loss: 0.000808851036708802\n",
      "Epoch 68/100, Loss: 0.00080339569831267\n",
      "Epoch 69/100, Loss: 0.0007861613412387669\n",
      "Epoch 70/100, Loss: 0.0007570403977297246\n",
      "Epoch 71/100, Loss: 0.0007205384899862111\n",
      "Epoch 72/100, Loss: 0.0006834923406131566\n",
      "Epoch 73/100, Loss: 0.0006522916373796761\n",
      "Epoch 74/100, Loss: 0.0006306873401626945\n",
      "Epoch 75/100, Loss: 0.0006188862025737762\n",
      "Epoch 76/100, Loss: 0.0006140442565083504\n",
      "Epoch 77/100, Loss: 0.0006117470329627395\n",
      "Epoch 78/100, Loss: 0.0006077999132685363\n",
      "Epoch 79/100, Loss: 0.0005996554391458631\n",
      "Epoch 80/100, Loss: 0.000587046321015805\n",
      "Epoch 81/100, Loss: 0.0005717196618206799\n",
      "Epoch 82/100, Loss: 0.00055648572742939\n",
      "Epoch 83/100, Loss: 0.0005440009408630431\n",
      "Epoch 84/100, Loss: 0.0005357566406019032\n",
      "Epoch 85/100, Loss: 0.0005316337337717414\n",
      "Epoch 86/100, Loss: 0.0005301371566019952\n",
      "Epoch 87/100, Loss: 0.0005291609559208155\n",
      "Epoch 88/100, Loss: 0.0005269092507660389\n",
      "Epoch 89/100, Loss: 0.000522580579854548\n",
      "Epoch 90/100, Loss: 0.0005165383918210864\n",
      "Epoch 91/100, Loss: 0.0005099645932205021\n",
      "Epoch 92/100, Loss: 0.0005042082630097866\n",
      "Epoch 93/100, Loss: 0.000500164576806128\n",
      "Epoch 94/100, Loss: 0.0004979460500180721\n",
      "Epoch 95/100, Loss: 0.0004969477886334062\n",
      "Epoch 96/100, Loss: 0.0004962154198437929\n",
      "Epoch 97/100, Loss: 0.0004949082504026592\n",
      "Epoch 98/100, Loss: 0.0004926411202177405\n",
      "Epoch 99/100, Loss: 0.0004895731108263135\n",
      "Epoch 100/100, Loss: 0.0004862425848841667\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "cell = GCGRUCell(n_neurons, torch.tensor(adj, dtype=torch.float32), n_gcn_nodes, s_index)\n",
    "model = GCGRUModel(cell, seq_len, n_gcn_nodes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "# Training\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train).squeeze()\n",
    "    loss = criterion(outputs[:, -1, 0].unsqueeze(1), y_train) # Select the first output node for comparison with y_train\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1732245113038,
     "user": {
      "displayName": "Yifei Wang",
      "userId": "04373107959264327198"
     },
     "user_tz": -480
    },
    "id": "sNSZrQ1rLHo9",
    "outputId": "87d5e37d-3762-4b5b-9b5a-c018379e0230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************\n",
      "R2: 0.9845036268234253\n",
      "RMSE: 0.023273538984219584\n",
      "MAE: 0.017209293320775032\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "\n",
    "    result = predictions[:, -1, 0].unsqueeze(1).numpy()\n",
    "\n",
    "# Metrics\n",
    "# print(result.shape)\n",
    "# print(y_test.shape)\n",
    "r2 = r2_score(y_test, result)\n",
    "rmse = sqrt(mean_squared_error(y_test, result))\n",
    "mae = mean_absolute_error(y_test, result)\n",
    "# re = avg_relative_error(y_test, result)\n",
    "\n",
    "print(\"***********************\")\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "# print(f\"Relative Error: {re}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
